# -*- coding: utf-8 -*-
"""EDASWAP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15BRaTKBxnfj28LfLRVQkftLHtoIxpCfZ
"""

!pip install gdrive_dataset
!pip install numpy
!pip install transformers
!pip install torchmetrics
!pip install pytorch_lightning

from gdrivedataset import loader
import os
from gdrivedataset import loader
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import random

!wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000327/data/20240827234036/code.tar.gz
# 다운로드한 파일의 압축 해제
!tar -xzvf code.tar.gz
# 압축 해제된 폴더의 내용 확인 (필요에 따라 수정)
!ls
#베이스라인코드

!wget https://aistages-api-public-prod.s3.amazonaws.com/app/Competitions/000327/data/data.tar.gz
# 아래 명령어로 압축을 해제해주세요
!tar -zxvf data.tar.gz
#데이터코드

data_train = pd.read_csv("/content/train.csv")
data_dev = pd.read_csv("/content/dev.csv")

import pandas as pd

def swap_sentence(df: pd.DataFrame) -> pd.DataFrame:
    """Sentence1과 Sentence2를 Swap하는 함수"""
    df_swapped = df.copy()

    # 조건에 맞는 데이터만 선택
    mask = ((df['label'] >= 0.5) & (df['label'] < 3.5)) | ((df['label'] >= 4.5) & (df['label'] < 5))
    df_swapped.loc[mask, ['sentence_1', 'sentence_2']] = df_swapped.loc[mask, ['sentence_2', 'sentence_1']].values

    return df_swapped

# Random Swap 적용
data_swapped = swap_sentence(data_train)

# label이 0인 값을 제거
data_swapped_nonzero = data_swapped[data_swapped['label'] != 0.0]

# 데이터 합치기
combined_data = pd.concat([data_train, data_swapped_nonzero], ignore_index=True)

# 결과 출력
print(f"원본 데이터 수: {data_train.shape[0]}")
print(f"스왑된 데이터 수 (label 0.0 제거): {data_swapped_nonzero.shape[0]}")
print(f"합친 데이터 수: {combined_data.shape[0]}")

#--------------------------------------------------------------------------
#간소화 시킨 코드입니다

#아래는 swap 하면서 확인했던 과정들 입니다

data_train.head()

import random

def swap_sentence(df: pd.DataFrame) -> pd.DataFrame:
    """Sentence1과 Sentence2를 Swap하는 함수"""
    df_swapped = df.copy()

    # 조건에 맞는 데이터만 선택
    mask = ((df['label'] >= 0.5) & (df['label'] < 3.5)) | ((df['label'] >= 4.5) & (df['label'] < 5))
    df_swapped.loc[mask, 'sentence_1'] = df['sentence_2']
    df_swapped.loc[mask, 'sentence_2'] = df['sentence_1']

    return df_swapped

data_train.head()

# Random Swap 적용
data_swapped = swap_sentence(data_train)
# 위치 바뀐
data_swapped.head()

# 원본 데이터 수
original_data_count = data_swapped.shape[0]

# label이 0인 값을 제거
data_swapped_nonzero = data_swapped[data_swapped['label'] != 0.0]

# 스왑된 데이터 수 (0인 값 제거 후)
data_swapped_nonzero.head(60)

swapped_count = data_swapped_nonzero.shape[0]
# 결과 확인
print(f"스왑된 데이터 수 (label 0.0 제거?): {swapped_count}")

# 스왑된 데이터 수
swapped_count = data_swapped_nonzero.shape[0]

# 원본 데이터 수
original_data_count = data_train.shape[0]

# 데이터 합치기
combined_data = pd.concat([data_train, data_swapped_nonzero], ignore_index=True)

# 결과 출력
print(f"원본 데이터 수: {original_data_count}")
print(f"스왑된 데이터 수 (label 0.0 제거): {swapped_count}")
print(f"합친 데이터 수: {combined_data.shape[0]}")

# 라벨 분포 시각화
plt.figure(figsize=(10, 5))
data_train['label'].hist(alpha=0.5, color='orange', label='sample Train Data', bins=20)
plt.legend()
plt.title('Label Distribution Before and After Random Swap')
plt.xlabel('Label')
plt.ylabel('Frequency')
plt.show()

# 라벨 분포 시각화
plt.figure(figsize=(10, 5))
combined_data['label'].hist(alpha=0.5, color='orange', label='sample Train Data', bins=20)
plt.legend()
plt.title('Label Distribution Before and After Random Swap')
plt.xlabel('Label')
plt.ylabel('Frequency')
plt.show()