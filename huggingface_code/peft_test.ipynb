{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA\n",
    "학습 시에는 일부 파라미터만 튜닝하지만, 해당 파라미터를 원래 모델에 얹는 형식이기 때문에 추론 시에는 원래 사용되는 모델의 사용량만큼의 리소스를 사용하게 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`r`**  \n",
    "- 원래의 모델을 작은 rank로 분해할 때 사용하는 매개변수로, 행렬에서 독립인 행 또는 열의 수를 의미  \n",
    "- 커지면 학습 시간과 학습 파라미터 수가 증가, 작아지면 연산량이 줄어들지만 성능이 낮아질 수 있음  \n",
    "- 하지만 r 값이 커진다고 해서 항상 성능 향상을 보장하는 것은 아님  \n",
    "\n",
    "**`lora_alpha`**  \n",
    "- rank와 함께 사용되는 변수  \n",
    "- 학습한 low rank의 파라미터를 가중치 몇을 곱해서 모델에 반영할 것인지 즉, fine-tuning한 파라미터들의 영향력을 얼마나 키울 것인지  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(task_type=TaskType.SEQ_CLS,\n",
    "                         inference_mode=False,\n",
    "                         r=16,\n",
    "                         lora_alpha=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"klue/roberta-small\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 886,273 || all params: 68,977,922 || trainable%: 1.2849\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "tokenization: 100%|██████████| 9324/9324 [00:03<00:00, 2886.47it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "tokenization: 100%|██████████| 550/550 [00:00<00:00, 2690.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataset import preprocess\n",
    "\n",
    "train_data = preprocess(task=\"train\", data_path='../../train_preprocess_v1.csv', model_name='klue/roberta-small', scale=True)\n",
    "valid_data = preprocess(task=\"train\", data_path='../../dev_preprocess_v1.csv', model_name='klue/roberta-small', scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: 4dau88s5\n",
      "Sweep URL: https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "sweep_config = {\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"pearson_corr\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"early_terminate\": {\n",
    "        'type': 'hyperband',\n",
    "        's': 3,\n",
    "        'eta': 3,\n",
    "        'max_iter': 100\n",
    "    }\n",
    "}\n",
    "\n",
    "parameters_dict = {\n",
    "    'max_epoch': {'values': [1, 3, 5]},\n",
    "    'batch_size': {'values': [8, 16]},\n",
    "    'learning_rate': {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 1e-5,\n",
    "        'max': 1e-3\n",
    "    },\n",
    "    'weight_decay': {\n",
    "        'distribution': 'uniform',\n",
    "        'min': 0.001,\n",
    "        'max': 0.1\n",
    "    },\n",
    "    'scheduler_patience': {'values': [3, 5, 7]}\n",
    "}\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project='lora-roberta-large-sweeps-test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    \n",
    "    predictions = logits.squeeze()\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    pearson_corr, _ = pearsonr(predictions, labels)\n",
    "\n",
    "    return {\"pearson_corr\": pearson_corr}\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        \n",
    "        training_arguments = TrainingArguments(\n",
    "            output_dir='./peft/',\n",
    "            report_to='wandb',\n",
    "            overwrite_output_dir=False,\n",
    "            num_train_epochs=config.max_epoch,\n",
    "            # learning_rate=config.learning_rate,\n",
    "            # weight_decay=config.weight_decay,\n",
    "            eval_strategy=\"epoch\",\n",
    "            per_device_train_batch_size=config.batch_size,\n",
    "            per_device_eval_batch_size=config.batch_size,\n",
    "            lr_scheduler_type='cosine', # 'linear', 'cosine', 'cosine_with_restarts', 'polynomial', 'constant', 'constant_with_warmup', 'inverse_sqrt'\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=training_arguments,\n",
    "            train_dataset=train_data,\n",
    "            eval_dataset=valid_data,\n",
    "            compute_metrics=compute_metrics,\n",
    "        )\n",
    "    \n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2cbl674i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007272648374404899\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.015552416343030569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_082534-2cbl674i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/2cbl674i' target=\"_blank\">morning-sweep-1</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/2cbl674i' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/2cbl674i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.032683</td>\n",
       "      <td>0.858285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.021902</td>\n",
       "      <td>0.864438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>0.020829</td>\n",
       "      <td>0.877517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>0.879824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.020658</td>\n",
       "      <td>0.882652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▂▁▂</td></tr><tr><td>eval/pearson_corr</td><td>▁▃▇▇█</td></tr><tr><td>eval/runtime</td><td>▁█▃▇▄</td></tr><tr><td>eval/samples_per_second</td><td>█▁▆▂▅</td></tr><tr><td>eval/steps_per_second</td><td>█▁▆▂▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>█▂▃▂▁</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02066</td></tr><tr><td>eval/pearson_corr</td><td>0.88265</td></tr><tr><td>eval/runtime</td><td>2.8248</td></tr><tr><td>eval/samples_per_second</td><td>194.702</td></tr><tr><td>eval/steps_per_second</td><td>12.39</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.48339</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.013</td></tr><tr><td>train_loss</td><td>0.0233</td></tr><tr><td>train_runtime</td><td>541.4888</td></tr><tr><td>train_samples_per_second</td><td>86.096</td></tr><tr><td>train_steps_per_second</td><td>5.383</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">morning-sweep-1</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/2cbl674i' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/2cbl674i</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_082534-2cbl674i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x9dotmjj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004336686175324083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.011304639489898924\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33moceann0315\u001b[0m (\u001b[33moceann010315\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_083450-x9dotmjj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/x9dotmjj' target=\"_blank\">prime-sweep-2</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/x9dotmjj' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/x9dotmjj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='583' max='583' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [583/583 01:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.879618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/pearson_corr</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁██</td></tr><tr><td>train/global_step</td><td>▁██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.0211</td></tr><tr><td>eval/pearson_corr</td><td>0.87962</td></tr><tr><td>eval/runtime</td><td>2.8172</td></tr><tr><td>eval/samples_per_second</td><td>195.232</td></tr><tr><td>eval/steps_per_second</td><td>12.424</td></tr><tr><td>total_flos</td><td>1260489806585856.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>583</td></tr><tr><td>train/grad_norm</td><td>0.25528</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.0127</td></tr><tr><td>train_loss</td><td>0.01229</td></tr><tr><td>train_runtime</td><td>108.538</td></tr><tr><td>train_samples_per_second</td><td>85.905</td></tr><tr><td>train_steps_per_second</td><td>5.371</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">prime-sweep-2</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/x9dotmjj' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/x9dotmjj</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_083450-x9dotmjj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m116p8wp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005118287996210905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.07674203732627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_083651-m116p8wp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/m116p8wp' target=\"_blank\">pious-sweep-3</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/m116p8wp' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/m116p8wp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>0.864061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>0.870238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.881841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.020435</td>\n",
       "      <td>0.882155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.020719</td>\n",
       "      <td>0.883115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▃▁▁▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▃███</td></tr><tr><td>eval/runtime</td><td>▆▃▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>▃▆██▁</td></tr><tr><td>eval/steps_per_second</td><td>▃▆██▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>█▇▁▁▅</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>▇█▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02072</td></tr><tr><td>eval/pearson_corr</td><td>0.88311</td></tr><tr><td>eval/runtime</td><td>2.8355</td></tr><tr><td>eval/samples_per_second</td><td>193.968</td></tr><tr><td>eval/steps_per_second</td><td>12.343</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.45743</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.0079</td></tr><tr><td>train_loss</td><td>0.00979</td></tr><tr><td>train_runtime</td><td>541.7223</td></tr><tr><td>train_samples_per_second</td><td>86.059</td></tr><tr><td>train_steps_per_second</td><td>5.381</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pious-sweep-3</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/m116p8wp' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/m116p8wp</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_083651-m116p8wp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n81xchdg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005603941744328166\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.018013831399319776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_084604-n81xchdg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/n81xchdg' target=\"_blank\">toasty-sweep-4</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/n81xchdg' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/n81xchdg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3498' max='3498' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3498/3498 05:49, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>0.858716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.021357</td>\n",
       "      <td>0.872883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.020148</td>\n",
       "      <td>0.885503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▂▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▅█</td></tr><tr><td>eval/runtime</td><td>▁▅█</td></tr><tr><td>eval/samples_per_second</td><td>█▄▁</td></tr><tr><td>eval/steps_per_second</td><td>█▄▁</td></tr><tr><td>train/epoch</td><td>▁▂▃▃▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▂▃▃▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▇█▃▃▁▆</td></tr><tr><td>train/learning_rate</td><td>█▇▅▄▂▁</td></tr><tr><td>train/loss</td><td>▇█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02015</td></tr><tr><td>eval/pearson_corr</td><td>0.8855</td></tr><tr><td>eval/runtime</td><td>2.9773</td></tr><tr><td>eval/samples_per_second</td><td>184.73</td></tr><tr><td>eval/steps_per_second</td><td>23.175</td></tr><tr><td>total_flos</td><td>3781469419757568.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>3498</td></tr><tr><td>train/grad_norm</td><td>0.63472</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.0083</td></tr><tr><td>train_loss</td><td>0.01192</td></tr><tr><td>train_runtime</td><td>349.2696</td></tr><tr><td>train_samples_per_second</td><td>80.087</td></tr><tr><td>train_steps_per_second</td><td>10.015</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-sweep-4</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/n81xchdg' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/n81xchdg</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_084604-n81xchdg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 609f4afv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00024864496875209863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0639336974626759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_085204-609f4afv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/609f4afv' target=\"_blank\">logical-sweep-5</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/609f4afv' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/609f4afv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1166' max='1166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1166/1166 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.021131</td>\n",
       "      <td>0.879581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/pearson_corr</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆██</td></tr><tr><td>train/global_step</td><td>▁▆██</td></tr><tr><td>train/grad_norm</td><td>█▁</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02113</td></tr><tr><td>eval/pearson_corr</td><td>0.87958</td></tr><tr><td>eval/runtime</td><td>2.9858</td></tr><tr><td>eval/samples_per_second</td><td>184.204</td></tr><tr><td>eval/steps_per_second</td><td>23.109</td></tr><tr><td>total_flos</td><td>1260489806585856.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>1166</td></tr><tr><td>train/grad_norm</td><td>0.66545</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0062</td></tr><tr><td>train_loss</td><td>0.00675</td></tr><tr><td>train_runtime</td><td>116.6948</td></tr><tr><td>train_samples_per_second</td><td>79.901</td></tr><tr><td>train_steps_per_second</td><td>9.992</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-5</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/609f4afv' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/609f4afv</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_085204-609f4afv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wx1cxkj8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.000673213128979755\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.02674017845698166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_085416-wx1cxkj8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/wx1cxkj8' target=\"_blank\">young-sweep-6</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/wx1cxkj8' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/wx1cxkj8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1749' max='1749' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1749/1749 05:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.022671</td>\n",
       "      <td>0.876908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.020707</td>\n",
       "      <td>0.876979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.884539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▁▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▁█</td></tr><tr><td>eval/runtime</td><td>▁▅█</td></tr><tr><td>eval/samples_per_second</td><td>█▄▁</td></tr><tr><td>eval/steps_per_second</td><td>█▄▁</td></tr><tr><td>train/epoch</td><td>▁▁▄▅▇██</td></tr><tr><td>train/global_step</td><td>▁▁▄▅▇██</td></tr><tr><td>train/grad_norm</td><td>▃█▁</td></tr><tr><td>train/learning_rate</td><td>█▄▁</td></tr><tr><td>train/loss</td><td>█▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02062</td></tr><tr><td>eval/pearson_corr</td><td>0.88454</td></tr><tr><td>eval/runtime</td><td>2.8281</td></tr><tr><td>eval/samples_per_second</td><td>194.479</td></tr><tr><td>eval/steps_per_second</td><td>12.376</td></tr><tr><td>total_flos</td><td>3781469419757568.0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1749</td></tr><tr><td>train/grad_norm</td><td>0.25989</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.0062</td></tr><tr><td>train_loss</td><td>0.00763</td></tr><tr><td>train_runtime</td><td>325.1753</td></tr><tr><td>train_samples_per_second</td><td>86.021</td></tr><tr><td>train_steps_per_second</td><td>5.379</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">young-sweep-6</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/wx1cxkj8' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/wx1cxkj8</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_085416-wx1cxkj8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 88rabjmw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002986540115781737\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.06697247473355082\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_085956-88rabjmw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/88rabjmw' target=\"_blank\">peach-sweep-7</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/88rabjmw' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/88rabjmw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.022085</td>\n",
       "      <td>0.885898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.022155</td>\n",
       "      <td>0.879336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.020780</td>\n",
       "      <td>0.880736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.020176</td>\n",
       "      <td>0.884634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.020625</td>\n",
       "      <td>0.884599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>██▃▁▃</td></tr><tr><td>eval/pearson_corr</td><td>█▁▂▇▇</td></tr><tr><td>eval/runtime</td><td>▇▁▇█▆</td></tr><tr><td>eval/samples_per_second</td><td>▂█▂▁▃</td></tr><tr><td>eval/steps_per_second</td><td>▂█▂▁▃</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>█▇▁▆▄</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>█▂▁▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02062</td></tr><tr><td>eval/pearson_corr</td><td>0.8846</td></tr><tr><td>eval/runtime</td><td>2.8301</td></tr><tr><td>eval/samples_per_second</td><td>194.341</td></tr><tr><td>eval/steps_per_second</td><td>12.367</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.36182</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.005</td></tr><tr><td>train_loss</td><td>0.00517</td></tr><tr><td>train_runtime</td><td>541.7638</td></tr><tr><td>train_samples_per_second</td><td>86.052</td></tr><tr><td>train_steps_per_second</td><td>5.381</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">peach-sweep-7</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/88rabjmw' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/88rabjmw</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_085956-88rabjmw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ax0csip3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0006880918431557524\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.022113129658625982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_090911-ax0csip3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ax0csip3' target=\"_blank\">snowy-sweep-8</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ax0csip3' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ax0csip3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.875757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.021945</td>\n",
       "      <td>0.879598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.886987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>0.891034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.019589</td>\n",
       "      <td>0.890033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▁▂</td></tr><tr><td>eval/pearson_corr</td><td>▁▃▆██</td></tr><tr><td>eval/runtime</td><td>█▁▆▂▆</td></tr><tr><td>eval/samples_per_second</td><td>▁█▃▇▃</td></tr><tr><td>eval/steps_per_second</td><td>▁█▃▇▃</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▃▅▁█▃</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>▂█▇▄▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.01959</td></tr><tr><td>eval/pearson_corr</td><td>0.89003</td></tr><tr><td>eval/runtime</td><td>2.8356</td></tr><tr><td>eval/samples_per_second</td><td>193.965</td></tr><tr><td>eval/steps_per_second</td><td>12.343</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.37095</td></tr><tr><td>train/learning_rate</td><td>3e-05</td></tr><tr><td>train/loss</td><td>0.0053</td></tr><tr><td>train_loss</td><td>0.00609</td></tr><tr><td>train_runtime</td><td>541.5697</td></tr><tr><td>train_samples_per_second</td><td>86.083</td></tr><tr><td>train_steps_per_second</td><td>5.383</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">snowy-sweep-8</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ax0csip3' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ax0csip3</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_090911-ax0csip3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gwl4amqy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004587643636279754\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.006244491957916803\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_091826-gwl4amqy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/gwl4amqy' target=\"_blank\">charmed-sweep-9</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/gwl4amqy' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/gwl4amqy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.887576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.020770</td>\n",
       "      <td>0.880386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.020189</td>\n",
       "      <td>0.891261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.019333</td>\n",
       "      <td>0.889572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>0.889304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>██▅▁▅</td></tr><tr><td>eval/pearson_corr</td><td>▆▁█▇▇</td></tr><tr><td>eval/runtime</td><td>▂█▅▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▇▁▄▇█</td></tr><tr><td>eval/steps_per_second</td><td>▆▁▄▇█</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▂▄▁█▃</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>█▇▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02008</td></tr><tr><td>eval/pearson_corr</td><td>0.8893</td></tr><tr><td>eval/runtime</td><td>2.824</td></tr><tr><td>eval/samples_per_second</td><td>194.76</td></tr><tr><td>eval/steps_per_second</td><td>12.394</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.29233</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>0.0039</td></tr><tr><td>train_loss</td><td>0.0044</td></tr><tr><td>train_runtime</td><td>541.6445</td></tr><tr><td>train_samples_per_second</td><td>86.071</td></tr><tr><td>train_steps_per_second</td><td>5.382</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">charmed-sweep-9</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/gwl4amqy' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/gwl4amqy</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_091826-gwl4amqy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cnpay9km with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008977068517585052\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.09113745172983446\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_092758-cnpay9km</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/cnpay9km' target=\"_blank\">cosmic-sweep-10</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/cnpay9km' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/cnpay9km</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5830' max='5830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5830/5830 09:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.843932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.860497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.024481</td>\n",
       "      <td>0.877792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.020229</td>\n",
       "      <td>0.884084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.020384</td>\n",
       "      <td>0.884610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▁▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▄▇██</td></tr><tr><td>eval/runtime</td><td>▁▃▄█▃</td></tr><tr><td>eval/samples_per_second</td><td>█▆▅▁▆</td></tr><tr><td>eval/steps_per_second</td><td>█▆▅▁▆</td></tr><tr><td>train/epoch</td><td>▁▂▂▂▃▃▄▄▅▅▆▆▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▄▄▅▅▆▆▆▇███</td></tr><tr><td>train/grad_norm</td><td>▁█▃▅▁▂▃▂▁▂▁</td></tr><tr><td>train/learning_rate</td><td>██▇▆▅▄▃▃▂▁▁</td></tr><tr><td>train/loss</td><td>▆█▇▆▅▄▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02038</td></tr><tr><td>eval/pearson_corr</td><td>0.88461</td></tr><tr><td>eval/runtime</td><td>2.9779</td></tr><tr><td>eval/samples_per_second</td><td>184.694</td></tr><tr><td>eval/steps_per_second</td><td>23.171</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>5830</td></tr><tr><td>train/grad_norm</td><td>0.35375</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0058</td></tr><tr><td>train_loss</td><td>0.01252</td></tr><tr><td>train_runtime</td><td>582.2444</td></tr><tr><td>train_samples_per_second</td><td>80.069</td></tr><tr><td>train_steps_per_second</td><td>10.013</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-sweep-10</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/cnpay9km' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/cnpay9km</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_092758-cnpay9km/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t4e4kyup with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0004905879945444923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.08346835890434127\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_093750-t4e4kyup</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/t4e4kyup' target=\"_blank\">distinctive-sweep-11</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/t4e4kyup' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/t4e4kyup</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5830' max='5830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5830/5830 09:42, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.030128</td>\n",
       "      <td>0.872446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007600</td>\n",
       "      <td>0.027819</td>\n",
       "      <td>0.868553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.020094</td>\n",
       "      <td>0.890734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.018844</td>\n",
       "      <td>0.891737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.019320</td>\n",
       "      <td>0.892097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▂▁▁</td></tr><tr><td>eval/pearson_corr</td><td>▂▁███</td></tr><tr><td>eval/runtime</td><td>▃▁▅▃█</td></tr><tr><td>eval/samples_per_second</td><td>▆█▄▆▁</td></tr><tr><td>eval/steps_per_second</td><td>▆█▄▆▁</td></tr><tr><td>train/epoch</td><td>▁▂▂▂▃▃▄▄▅▅▆▆▆▇███</td></tr><tr><td>train/global_step</td><td>▁▂▂▂▃▃▄▄▅▅▆▆▆▇███</td></tr><tr><td>train/grad_norm</td><td>▇█▃▆▃▇▄▄▆▃▁</td></tr><tr><td>train/learning_rate</td><td>██▇▆▅▄▃▃▂▁▁</td></tr><tr><td>train/loss</td><td>███▆▅▄▃▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.01932</td></tr><tr><td>eval/pearson_corr</td><td>0.8921</td></tr><tr><td>eval/runtime</td><td>2.9931</td></tr><tr><td>eval/samples_per_second</td><td>183.753</td></tr><tr><td>eval/steps_per_second</td><td>23.053</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>5830</td></tr><tr><td>train/grad_norm</td><td>0.1981</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0046</td></tr><tr><td>train_loss</td><td>0.00637</td></tr><tr><td>train_runtime</td><td>582.214</td></tr><tr><td>train_samples_per_second</td><td>80.074</td></tr><tr><td>train_steps_per_second</td><td>10.014</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-sweep-11</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/t4e4kyup' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/t4e4kyup</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_093750-t4e4kyup/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: o5kejozn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008771834760350599\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0393666254190756\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_094739-o5kejozn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/o5kejozn' target=\"_blank\">devoted-sweep-12</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/o5kejozn' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/o5kejozn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.023303</td>\n",
       "      <td>0.873968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.023368</td>\n",
       "      <td>0.866952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>0.885323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.019641</td>\n",
       "      <td>0.888457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.020127</td>\n",
       "      <td>0.887593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>██▃▁▂</td></tr><tr><td>eval/pearson_corr</td><td>▃▁▇██</td></tr><tr><td>eval/runtime</td><td>▇█▂▁▅</td></tr><tr><td>eval/samples_per_second</td><td>▂▁▇█▄</td></tr><tr><td>eval/steps_per_second</td><td>▂▁▇█▄</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▄█▆▁▇</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>█▇▅▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02013</td></tr><tr><td>eval/pearson_corr</td><td>0.88759</td></tr><tr><td>eval/runtime</td><td>2.8243</td></tr><tr><td>eval/samples_per_second</td><td>194.739</td></tr><tr><td>eval/steps_per_second</td><td>12.392</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.54714</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.005</td></tr><tr><td>train_loss</td><td>0.00693</td></tr><tr><td>train_runtime</td><td>541.588</td></tr><tr><td>train_samples_per_second</td><td>86.08</td></tr><tr><td>train_steps_per_second</td><td>5.382</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-sweep-12</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/o5kejozn' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/o5kejozn</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_094739-o5kejozn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dbcwfo91 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007588042003345904\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.07999891418251158\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_095647-dbcwfo91</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/dbcwfo91' target=\"_blank\">usual-sweep-13</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/dbcwfo91' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/dbcwfo91</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:02, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.026129</td>\n",
       "      <td>0.861564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.871790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.021342</td>\n",
       "      <td>0.885481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.020404</td>\n",
       "      <td>0.882493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.884452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▂▁▁</td></tr><tr><td>eval/pearson_corr</td><td>▁▄█▇█</td></tr><tr><td>eval/runtime</td><td>█▂▁▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▁▇█▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▁▇█▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▁█▂▂▂</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>██▄▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02079</td></tr><tr><td>eval/pearson_corr</td><td>0.88445</td></tr><tr><td>eval/runtime</td><td>2.8274</td></tr><tr><td>eval/samples_per_second</td><td>194.524</td></tr><tr><td>eval/steps_per_second</td><td>12.379</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.37135</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.004</td></tr><tr><td>train_loss</td><td>0.00532</td></tr><tr><td>train_runtime</td><td>542.3393</td></tr><tr><td>train_samples_per_second</td><td>85.961</td></tr><tr><td>train_steps_per_second</td><td>5.375</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">usual-sweep-13</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/dbcwfo91' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/dbcwfo91</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_095647-dbcwfo91/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bo7wlbsp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 6.333963433213537e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.06215745264211588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_100555-bo7wlbsp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/bo7wlbsp' target=\"_blank\">skilled-sweep-14</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/bo7wlbsp' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/bo7wlbsp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='583' max='583' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [583/583 01:48, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.019837</td>\n",
       "      <td>0.886624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/pearson_corr</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁██</td></tr><tr><td>train/global_step</td><td>▁██</td></tr><tr><td>train/grad_norm</td><td>▁</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.01984</td></tr><tr><td>eval/pearson_corr</td><td>0.88662</td></tr><tr><td>eval/runtime</td><td>2.8251</td></tr><tr><td>eval/samples_per_second</td><td>194.687</td></tr><tr><td>eval/steps_per_second</td><td>12.389</td></tr><tr><td>total_flos</td><td>1260489806585856.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>583</td></tr><tr><td>train/grad_norm</td><td>0.19892</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0026</td></tr><tr><td>train_loss</td><td>0.00258</td></tr><tr><td>train_runtime</td><td>108.6974</td></tr><tr><td>train_samples_per_second</td><td>85.779</td></tr><tr><td>train_steps_per_second</td><td>5.364</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">skilled-sweep-14</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/bo7wlbsp' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/bo7wlbsp</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_100555-bo7wlbsp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ud6v8lj5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0008695137645911516\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.006719989813688341\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_100824-ud6v8lj5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ud6v8lj5' target=\"_blank\">solar-sweep-15</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ud6v8lj5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ud6v8lj5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2915' max='2915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2915/2915 09:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.024092</td>\n",
       "      <td>0.868828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.025315</td>\n",
       "      <td>0.847625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>0.882551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.020151</td>\n",
       "      <td>0.883925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.020663</td>\n",
       "      <td>0.885362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▆█▃▁▂</td></tr><tr><td>eval/pearson_corr</td><td>▅▁▇██</td></tr><tr><td>eval/runtime</td><td>▁▆█▂▄</td></tr><tr><td>eval/samples_per_second</td><td>█▃▁▇▅</td></tr><tr><td>eval/steps_per_second</td><td>█▃▁▇▅</td></tr><tr><td>train/epoch</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/global_step</td><td>▁▁▂▃▄▅▅▆▇██</td></tr><tr><td>train/grad_norm</td><td>▁█▁▂▁</td></tr><tr><td>train/learning_rate</td><td>█▆▄▂▁</td></tr><tr><td>train/loss</td><td>▇█▆▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.02066</td></tr><tr><td>eval/pearson_corr</td><td>0.88536</td></tr><tr><td>eval/runtime</td><td>2.8305</td></tr><tr><td>eval/samples_per_second</td><td>194.309</td></tr><tr><td>eval/steps_per_second</td><td>12.365</td></tr><tr><td>total_flos</td><td>6302449032929280.0</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>2915</td></tr><tr><td>train/grad_norm</td><td>0.39852</td></tr><tr><td>train/learning_rate</td><td>4e-05</td></tr><tr><td>train/loss</td><td>0.0041</td></tr><tr><td>train_loss</td><td>0.00571</td></tr><tr><td>train_runtime</td><td>546.987</td></tr><tr><td>train_samples_per_second</td><td>85.231</td></tr><tr><td>train_steps_per_second</td><td>5.329</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-15</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ud6v8lj5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/ud6v8lj5</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_100824-ud6v8lj5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e2jr71kn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 8\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00021611712685107887\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 7\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.021838930764760456\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_101738-e2jr71kn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/e2jr71kn' target=\"_blank\">youthful-sweep-16</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/e2jr71kn' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/e2jr71kn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1166' max='1166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1166/1166 01:56, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearson Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.020104</td>\n",
       "      <td>0.884851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/pearson_corr</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▆██</td></tr><tr><td>train/global_step</td><td>▁▆██</td></tr><tr><td>train/grad_norm</td><td>▁█</td></tr><tr><td>train/learning_rate</td><td>█▁</td></tr><tr><td>train/loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.0201</td></tr><tr><td>eval/pearson_corr</td><td>0.88485</td></tr><tr><td>eval/runtime</td><td>2.9853</td></tr><tr><td>eval/samples_per_second</td><td>184.234</td></tr><tr><td>eval/steps_per_second</td><td>23.113</td></tr><tr><td>total_flos</td><td>1260489806585856.0</td></tr><tr><td>train/epoch</td><td>1</td></tr><tr><td>train/global_step</td><td>1166</td></tr><tr><td>train/grad_norm</td><td>0.5394</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>0.0038</td></tr><tr><td>train_loss</td><td>0.00407</td></tr><tr><td>train_runtime</td><td>116.7889</td></tr><tr><td>train_samples_per_second</td><td>79.836</td></tr><tr><td>train_steps_per_second</td><td>9.984</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">youthful-sweep-16</strong> at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/e2jr71kn' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/e2jr71kn</a><br/> View project at: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240924_101738-e2jr71kn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6qtupb2n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0007835565249095074\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmax_epoch: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tscheduler_patience: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.08725169781123476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/sh/level1-semantictextsimilarity-nlp-06/huggingface_code/wandb/run-20240924_101950-6qtupb2n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/6qtupb2n' target=\"_blank\">bright-sweep-17</a></strong> to <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/sweeps/4dau88s5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/6qtupb2n' target=\"_blank\">https://wandb.ai/oceann010315/lora-roberta-large-sweeps-test/runs/6qtupb2n</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='179' max='583' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [179/583 00:31 < 01:12, 5.55 it/s, Epoch 0.31/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForSequenceClassification\n",
    "import os\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from pandas import read_csv\n",
    "\n",
    "model_path = './peft/checkpoint-10000'\n",
    "\n",
    "with open(os.path.join(model_path, 'adapter_config.json')) as f:\n",
    "        model_config = json.load(f)\n",
    "    \n",
    "model = AutoPeftModelForSequenceClassification.from_pretrained(model_path, num_labels=1)\n",
    "\n",
    "test_data = preprocess(task=\"test\", data_path='../../test_preprocess_v1.csv', model_name=model_config['base_model_name_or_path'])\n",
    "test_loader = DataLoader(test_data, shuffle=False)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "outputs = []\n",
    "for batch in test_loader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        predictions = model(**batch)\n",
    "        outputs.append(predictions.logits)\n",
    "\n",
    "outputs = list(round(float(i), 1) for i in torch.cat(outputs))\n",
    "\n",
    "sample_csv = read_csv('../../sample_submission.csv')\n",
    "sample_csv['target'] = outputs\n",
    "\n",
    "sample_csv.to_csv(os.path.join(model_path, 'output.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "baseline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
