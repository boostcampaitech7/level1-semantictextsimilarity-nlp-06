{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 앙상블 사용법\n",
    "클래스는 `ensemble.py`에서 확인  \n",
    "\n",
    "**`config_paths`**  \n",
    "fine-tuning 시 사용했던 config.yaml의 경로를 string list로 입력  \n",
    "이때 모델과 config.yaml은 해당 위치의 `models`라는 폴더 안에 넣어두기  \n",
    "config.yaml의 model_name에서 배포자명을 제외한 모델의 이름과 저장한 pt 파일의 이름이 일치하도록 하기(문제가 된다면 수정 예정)  \n",
    "\n",
    "**`base_predictions()`**  \n",
    "fine-tuning을 수행한 LLM들을 사용해서 base predictions를 추출  \n",
    "데이터 개수만큼의 행, 모델 수만큼의 열이 생성  \n",
    "\n",
    "**'stacking`, `kfold_stacking`, `soft_voting`**  \n",
    "각각 기본 stacking, soft voting, kfold stacking으로 메타 모델을 학습  \n",
    "clf 인자에 'linear'를 입력하면 LinearRegression을, 'lgbm'을 입력하면 LightBGM 모델을 사용하고 클래스의 멤버 변수로 등록  \n",
    "clf를 바꾸고 싶다면 clf 인자를 변경해서 함수를 다시 호출하면 됨  \n",
    "kfold stacking은 원래 kfold를 적용한 데이터로 LLM부터 학습해야 하지만 시간 관계 상, 리소스 관계 상 메타 모델에만 k-fold를 적용하는 방식으로 구현  \n",
    "n 값으로 몇 개의 fold를 사용할지 지정  \n",
    "\n",
    "**`inference`**  \n",
    "sample_submission.csv를 읽어와 앙상블 결과 저장  \n",
    "is_voting이 True이면 soft voting 결과를 사용하고, False이면 stacking과 kfold_stacking 중 가장 마지막에 사용한 classifier를 기준으로 추론 수행  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right now using \"deliciouscat/kf-deberta-base-cross-sts\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenization: 100%|██████████| 9324/9324 [00:03<00:00, 2926.44it/s]\n",
      "tokenization: 100%|██████████| 550/550 [00:00<00:00, 3070.08it/s]\n",
      "tokenization: 100%|██████████| 1100/1100 [00:00<00:00, 2883.20it/s]\n",
      "base prediction for train data: 100%|██████████| 583/583 [02:14<00:00,  4.34it/s]\n",
      "base prediction for valid data: 100%|██████████| 35/35 [00:07<00:00,  4.44it/s]\n",
      "base prediction for test data: 100%|██████████| 1100/1100 [00:30<00:00, 36.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Right now using \"deliciouscat/kf-deberta-base-cross-sts\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenization: 100%|██████████| 9324/9324 [00:03<00:00, 2942.45it/s]\n",
      "tokenization: 100%|██████████| 550/550 [00:00<00:00, 3153.90it/s]\n",
      "tokenization: 100%|██████████| 1100/1100 [00:00<00:00, 2918.78it/s]\n",
      "base prediction for train data: 100%|██████████| 583/583 [02:13<00:00,  4.37it/s]\n",
      "base prediction for valid data: 100%|██████████| 35/35 [00:07<00:00,  4.44it/s]\n",
      "base prediction for test data: 100%|██████████| 1100/1100 [00:30<00:00, 36.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(9324, 2) (9324, 1)\n",
      "(550, 2) (550, 1)\n",
      "(1100, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ensemble import Ensemble\n",
    "\n",
    "config_paths = ['./models/kf_deberta_cross_sts_config.yaml', './models/kf_deberta_cross_sts_config.yaml']\n",
    "ensemble = Ensemble(config_paths=config_paths,\n",
    "                    train_path='../../train_preprocess_v1.csv',\n",
    "                    valid_path='../../dev_preprocess_v1.csv',\n",
    "                    test_path='../../test_preprocess_v1.csv')\n",
    "\n",
    "X_train_base_, y_train_, X_valid_base_, y_valid_, X_test_ = ensemble.base_predictions()\n",
    "print(X_train_base_.shape, y_train_.shape)\n",
    "print(X_valid_base_.shape, y_valid_.shape)\n",
    "print(X_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============== linear result ==============\n",
      "    train pearson sim: [0.99857559]\n",
      "    valid pearson sim: [0.92838911]\n",
      "==========================================\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000215 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 9324, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.849968\n",
      "============== lgbm result ==============\n",
      "    train pearson sim: [0.99869295]\n",
      "    valid pearson sim: [0.92851294]\n",
      "==========================================\n",
      "\n",
      "\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99857559]\n",
      "    valid pearson sim: [0.92838911]\n",
      "==========================================\n",
      "\n",
      "\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99860786]\n",
      "    k-valid pearson sim: [0.99844497]\n",
      "    valid pearson sim: [0.99844497]\n",
      "==========================================\n",
      "\n",
      "\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99856262]\n",
      "    k-valid pearson sim: [0.9986258]\n",
      "    valid pearson sim: [0.9986258]\n",
      "==========================================\n",
      "\n",
      "\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99854456]\n",
      "    k-valid pearson sim: [0.99869849]\n",
      "    valid pearson sim: [0.99869849]\n",
      "==========================================\n",
      "\n",
      "\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.9985721]\n",
      "    k-valid pearson sim: [0.99859489]\n",
      "    valid pearson sim: [0.99859489]\n",
      "==========================================\n",
      "\n",
      "\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99859083]\n",
      "    k-valid pearson sim: [0.99851419]\n",
      "    valid pearson sim: [0.99851419]\n",
      "==========================================\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7459, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.850811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99872998]\n",
      "    k-valid pearson sim: [0.9984905]\n",
      "    valid pearson sim: [0.9984905]\n",
      "==========================================\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000144 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7459, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.839697\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99869897]\n",
      "    k-valid pearson sim: [0.99867778]\n",
      "    valid pearson sim: [0.99867778]\n",
      "==========================================\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7459, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.864137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99866779]\n",
      "    k-valid pearson sim: [0.99874458]\n",
      "    valid pearson sim: [0.99874458]\n",
      "==========================================\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7459, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.844135\n",
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99869724]\n",
      "    k-valid pearson sim: [0.99865659]\n",
      "    valid pearson sim: [0.99865659]\n",
      "==========================================\n",
      "\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 7460, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.851059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== soft voting result ===========\n",
      "    train pearson sim: [0.99871699]\n",
      "    k-valid pearson sim: [0.9985408]\n",
      "    valid pearson sim: [0.9985408]\n",
      "==========================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ensemble.stacking(clf=\"linear\")\n",
    "ensemble.stacking(clf=\"lgbm\")\n",
    "ensemble.soft_voting()\n",
    "ensemble.kfold_stacking(\"linear\", 3)\n",
    "ensemble.kfold_stacking(\"lgbm\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 510\n",
      "[LightGBM] [Info] Number of data points in the train set: 9324, number of used features: 2\n",
      "[LightGBM] [Info] Start training from score 1.849968\n",
      "============== lgbm result ==============\n",
      "    train pearson sim: [0.99869295]\n",
      "    valid pearson sim: [0.92851294]\n",
      "==========================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "ensemble.stacking(\"lgbm\")\n",
    "ensemble.inference(is_voting=False, submission_path='../../sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
